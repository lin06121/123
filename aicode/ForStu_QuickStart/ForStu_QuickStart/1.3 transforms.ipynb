{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d3b27d6",
   "metadata": {},
   "source": [
    "# 数据变换 Transforms\n",
    "\n",
    "通常情况下，直接加载的原始数据并不能直接送入神经网络进行训练，此时我们需要对其进行数据预处理。\n",
    "\n",
    "`mindspore.dataset`提供了面向图像、文本等不同数据类型的Transforms，同时也支持使用Lambda函数。\n",
    "\n",
    "所有的Transforms均可通过`map`方法传入，实现对指定数据列的处理,下面分别对其进行介绍。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35860e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from download import download\n",
    "from mindspore.dataset import transforms, vision, text\n",
    "from mindspore.dataset import GeneratorDataset, MnistDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ccb105c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Transforms 模块\n",
    "\n",
    "`mindspore.dataset.transforms`模块支持一系列通用Transforms。这里我们以`Compose`为例，介绍其使用方式。\n",
    "\n",
    "其他Transforms方法：\n",
    "- OneHot：将标签转换为one-hot编码；\n",
    "- TypeCast：转换数据类型\n",
    "- ...\n",
    "\n",
    "### Compose\n",
    "\n",
    "`Compose`接收一个数据增强操作序列，然后将其组合成单个数据增强操作。我们仍基于Mnist数据集呈现Transforms的应用效果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "118949f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/notebook/datasets/MNIST_Data.zip (10.3 MB)\n",
      "\n",
      "file_sizes: 100%|██████████████████████████| 10.8M/10.8M [00:00<00:00, 12.1MB/s]\n",
      "Extracting zip file...\n",
      "Successfully downloaded / unzipped to ./\n"
     ]
    }
   ],
   "source": [
    "# Download data from open datasets\n",
    "\n",
    "url = \"https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/\" \\\n",
    "      \"notebook/datasets/MNIST_Data.zip\"\n",
    "path = download(url, \"./\", kind=\"zip\", replace=True)\n",
    "\n",
    "train_dataset = MnistDataset('MNIST_Data/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d78af277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "image, label = next(train_dataset.create_tuple_iterator())\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49d3aed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#创建组合变换\n",
    "composed = transforms.Compose(\n",
    "    [\n",
    "        vision.Rescale(1.0 / 255.0, 0), # 将像素值缩放为0~1\n",
    "        vision.Normalize(mean=(0.1307,), std=(0.3081,)),\n",
    "        vision.HWC2CHW() #从高度×宽度×通道-->通道×高度×宽度\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fbd63bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = train_dataset.map(composed, 'image')\n",
    "image, label = next(train_dataset.create_tuple_iterator())\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92560507",
   "metadata": {},
   "source": [
    "## Vision 模块\n",
    "\n",
    "`mindspore.dataset.vision`模块提供一系列针对图像数据的Transforms。在Mnist数据处理过程中，使用了`Rescale`、`Normalize`和`HWC2CHW`变换。下面对其进行详述。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07ad972",
   "metadata": {},
   "source": [
    "### Rescale\n",
    "\n",
    "`Rescale`变换用于调整图像像素值的大小，包括两个参数：\n",
    "\n",
    "- rescale：缩放因子。\n",
    "- shift：平移因子。\n",
    "\n",
    "图像的每个像素将根据这两个参数进行调整，输出的像素值为$output_{i} = input_{i} * rescale + shift$。\n",
    "\n",
    "这里我们先使用numpy随机生成一个像素值在\\[0, 255\\]的图像，将其像素值进行缩放。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0d51957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[105  28 225 ...  42 168  56]\n",
      " [201 129 228 ... 201 190 171]\n",
      " [142 194   5 ...  94 149  39]\n",
      " ...\n",
      " [ 56 253 166 ...  23 148 110]\n",
      " [225 141  66 ... 218 139  15]\n",
      " [203 179  14 ... 125 204 175]]\n"
     ]
    }
   ],
   "source": [
    "random_np = np.random.randint(0, 255, (48, 48), np.uint8)\n",
    "random_image = Image.fromarray(random_np)\n",
    "print(random_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7da807",
   "metadata": {},
   "source": [
    "为了更直观地呈现Transform前后的数据对比，我们使用Transforms的[Eager模式](https://www.mindspore.cn/tutorials/zh-CN/r2.3/advanced/dataset/eager.html)进行演示。首先实例化Transform对象，然后调用对象进行数据处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5b6dacc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.41176474 0.10980393 0.882353   ... 0.16470589 0.65882355 0.21960786]\n",
      " [0.78823537 0.5058824  0.8941177  ... 0.78823537 0.74509805 0.67058825]\n",
      " [0.5568628  0.7607844  0.01960784 ... 0.36862746 0.58431375 0.15294118]\n",
      " ...\n",
      " [0.21960786 0.9921569  0.6509804  ... 0.09019608 0.5803922  0.43137258]\n",
      " [0.882353   0.5529412  0.25882354 ... 0.854902   0.54509807 0.05882353]\n",
      " [0.7960785  0.7019608  0.05490196 ... 0.4901961  0.8000001  0.6862745 ]]\n"
     ]
    }
   ],
   "source": [
    "rescale = vision.Rescale(1.0 / 255.0, 0)\n",
    "rescaled_image = rescale(random_image)\n",
    "print(rescaled_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b2ebc4",
   "metadata": {},
   "source": [
    "可以看到，使用`Rescale`后的每个像素值都进行了缩放。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8eaa27c",
   "metadata": {},
   "source": [
    "### Normalize\n",
    "\n",
    "[Normalize](https://www.mindspore.cn/docs/zh-CN/r2.3/api_python/dataset_vision/mindspore.dataset.vision.Normalize.html)变换用于对输入图像的归一化，包括三个参数：\n",
    "\n",
    "- mean：图像每个通道的均值。\n",
    "- std：图像每个通道的标准差。\n",
    "- is_hwc：bool值，输入图像的格式。\n",
    "True为(height, width, channel)，False为(channel, height, width)。\n",
    "\n",
    "图像的每个通道将根据`mean`和`std`进行调整，计算公式为$output_{c} = \\frac{input_{c} - mean_{c}}{std_{c}}$，其中 $c$代表通道索引。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5dbafdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.9122518  -0.06782239  2.4396398  ...  0.11037287  1.7141304\n",
      "   0.28856817]\n",
      " [ 2.1341622   1.2177293   2.4778247  ...  2.1341622   1.9941516\n",
      "   1.7523152 ]\n",
      " [ 1.3831964   2.0450647  -0.3605718  ...  0.77224106  1.472294\n",
      "   0.07218818]\n",
      " ...\n",
      " [ 0.28856817  2.7960305   1.688674   ... -0.13146357  1.4595658\n",
      "   0.9758929 ]\n",
      " [ 2.4396398   1.3704681   0.41585052 ...  2.3505423   1.3450117\n",
      "  -0.23328944]\n",
      " [ 2.1596189   1.854141   -0.24601768 ...  1.1668164   2.172347\n",
      "   1.803228  ]]\n"
     ]
    }
   ],
   "source": [
    "normalize = vision.Normalize(mean=(0.1307,), std=(0.3081,))\n",
    "normalized_image = normalize(rescaled_image)\n",
    "print(normalized_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb5b141",
   "metadata": {},
   "source": [
    "### HWC2CHW\n",
    "\n",
    "`HWC2CHW`变换用于转换图像格式。在不同的硬件设备中可能会对(height, width, channel)或(channel, height, width)两种不同格式有针对性优化。MindSpore设置HWC为默认图像格式，在有CHW格式需求时，可使用该变换进行处理。\n",
    "\n",
    "这里我们先将前文中`normalized_image`处理为HWC格式，然后进行转换。可以看到转换前后的shape发生了变化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91b8e393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48, 48, 1) (1, 48, 48)\n"
     ]
    }
   ],
   "source": [
    "hwc_image = np.expand_dims(normalized_image, -1)\n",
    "hwc2chw = vision.HWC2CHW()\n",
    "chw_image = hwc2chw(hwc_image)\n",
    "print(hwc_image.shape, chw_image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c40019",
   "metadata": {},
   "source": [
    "## Text 模块"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e4a98c",
   "metadata": {},
   "source": [
    "`mindspore.dataset.text`模块提供一系列针对文本数据的Transforms。与图像数据不同，文本数据需要有分词（Tokenize）、构建词表、Token转Index等操作。这里简单介绍其使用方法。\n",
    "\n",
    "首先我们定义一段文本，作为待处理的数据，并使用`GeneratorDataset`进行加载。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b11fa76",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = ['Welcome to Beijing']\n",
    "test_dataset = GeneratorDataset(texts, 'text')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371f2100",
   "metadata": {},
   "source": [
    "### PythonTokenizer\n",
    "\n",
    "分词（Tokenize）操作是文本数据的基础处理方法，MindSpore提供多种不同的Tokenizer。这里我们选择基础的`PythonTokenizer`举例，此Tokenizer允许用户自由实现分词策略。随后我们利用`map`操作将此分词器应用到输入的文本中，对其进行分词。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0ee1b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Tensor(shape=[3], dtype=String, value= ['Welcome', 'to', 'Beijing'])]\n"
     ]
    }
   ],
   "source": [
    "#先定义分词的规则\n",
    "def my_tokenizer(content):\n",
    "    return content.split()\n",
    "\n",
    "test_dataset = test_dataset.map(text.PythonTokenizer(my_tokenizer))\n",
    "print(next(test_dataset.create_tuple_iterator()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fa351c",
   "metadata": {},
   "source": [
    "### Lookup\n",
    "\n",
    "`Lookup`为词表映射变换，用来将Token转换为Index。\n",
    "\n",
    "在使用`Lookup`前，需要构造词表，一般可以加载已有的词表，或使用`text.Vocab`生成词表。这里我们选择使用`text.Vocab.from_dataset`方法从数据集中生成词表。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ef22eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = text.Vocab.from_dataset(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430258b3",
   "metadata": {},
   "source": [
    "获得词表后我们可以使用`vocab`方法查看词表。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b43487a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Beijing': 0, 'Welcome': 1, 'to': 2}\n"
     ]
    }
   ],
   "source": [
    "print(vocab.vocab())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b01e3e",
   "metadata": {},
   "source": [
    "生成词表后，可以使用`lookup` 配合`map`方法进行词表映射变换，将Token转为Index。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f027b92c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Tensor(shape=[3], dtype=Int32, value= [1, 2, 0])]\n"
     ]
    }
   ],
   "source": [
    "test_dataset = test_dataset.map(text.Lookup(vocab))\n",
    "print(next(test_dataset.create_tuple_iterator()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e897f53",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Lambda 自定义数据变换\n",
    "\n",
    "Lambda函数不需要名字即可定义，表达式会在调用时被求值。\n",
    "\n",
    "Lambda Transforms可以加载任意定义的Lambda函数，提供足够的灵活度。\n",
    "\n",
    "在这里，我们首先使用一个简单的Lambda函数，对输入数据乘2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5db0d96d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[Tensor(shape=[], dtype=Int64, value= 2)], [Tensor(shape=[], dtype=Int64, value= 4)], [Tensor(shape=[], dtype=Int64, value= 6)]]\n"
     ]
    }
   ],
   "source": [
    "test_dataset = GeneratorDataset([1, 2, 3], 'data', shuffle=False)\n",
    "test_dataset = test_dataset.map(lambda x: x * 2)\n",
    "print(list(test_dataset.create_tuple_iterator()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df002bd",
   "metadata": {},
   "source": [
    "可以看到`map`传入Lambda函数后，迭代获得数据进行了乘2操作。\n",
    "\n",
    "也可以定义较复杂的函数，配合Lambda函数实现复杂数据处理："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "142138e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(x):\n",
    "    return x * x + 2\n",
    "\n",
    "test_dataset = test_dataset.map(lambda x: func(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83d49720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[Tensor(shape=[], dtype=Int64, value= 6)], [Tensor(shape=[], dtype=Int64, value= 18)], [Tensor(shape=[], dtype=Int64, value= 38)]]\n"
     ]
    }
   ],
   "source": [
    "print(list(test_dataset.create_tuple_iterator()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ms2.4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
