{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 逻辑回归\n",
    "\n",
    "这项作业将指导你建立一个逻辑回归分类器来识别猫。\n",
    "\n",
    "**Instructions:**\n",
    "- 尽可能不要在代码中使用循环，除非告诉你可以这么做~\n",
    "\n",
    "**You will learn to:**\n",
    "- 算法总体架构:\n",
    "    - 初始化参数                            。\n",
    "    - 计算损失函数及梯度\n",
    "    - 使用梯度下降\n",
    "- 按照正确顺序将上面的三个函数整合到一个主函数中"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T11:34:18.681815Z",
     "start_time": "2025-03-04T11:34:17.364472Z"
    }
   },
   "source": [
    "#可能你需要安装以下库\n",
    "!pip install opencv-python"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\liyy\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\liyy\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from opencv-python) (2.2.3)\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - 库文件##\n",
    "\n",
    "运行以下代码来导入需要的包。\n",
    "- [numpy](www.numpy.org) 是用来使用Python进行科学计算的。\n",
    "- [h5py](http://www.h5py.org) 是用来与存储在H5文件中的数据集进行交互的。\n",
    "- [matplotlib](http://matplotlib.org) 是一个用Python绘制图形的著名的库。\n",
    "- [PIL](http://www.pythonware.com/products/pil/) and [scipy](https://www.scipy.org/) 是用来测试你所训练的模型的。\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T11:34:21.588231Z",
     "start_time": "2025-03-04T11:34:21.172823Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import scipy\n",
    "from PIL import Image\n",
    "#from scipy import ndimage\n",
    "import cv2\n",
    "from lr_utils import load_dataset\n",
    "\n",
    "%matplotlib inline"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 2 - 问题描述 ##\n",
    "\n",
    "你的数据集 (\"data.h5\")包括:\n",
    "    - 标记为cat（y=1）或non-cat（y=0）的训练集图片m_train\n",
    "    - 标记为cat或non-cat的测试集图片m_test\n",
    "    - 图片shape为(num_px, num_px, 3) ,3代表\"RGB\"3个通道.(可以发现，每张图片都是正方形)\n",
    "\n",
    "你将构建一个简单的图像识别算法，将图片正确分类为cat或non-cat。              \n",
    "\n",
    "运行以下代码来加载数据:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T11:34:23.935609Z",
     "start_time": "2025-03-04T11:34:23.819604Z"
    }
   },
   "source": [
    "# Loading the data (cat/non-cat)\n",
    "train_set_x_orig, train_set_y, test_set_x_orig, test_set_y, classes = load_dataset()\n",
    "print(train_set_x_orig.shape)\n",
    "print(train_set_y.shape)\n",
    "print(test_set_x_orig.shape)\n",
    "print(test_set_y.shape)\n",
    "print(classes)"
   ],
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to synchronously open file (unable to open file: name = 'datasets/train_catvnoncat.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Loading the data (cat/non-cat)\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m train_set_x_orig, train_set_y, test_set_x_orig, test_set_y, classes \u001B[38;5;241m=\u001B[39m \u001B[43mload_dataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(train_set_x_orig\u001B[38;5;241m.\u001B[39mshape)\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(train_set_y\u001B[38;5;241m.\u001B[39mshape)\n",
      "File \u001B[1;32mC:\\Users\\liyy\\Downloads\\hw-Numpy、LR\\hw-Numpy、LR\\lr_utils.py:6\u001B[0m, in \u001B[0;36mload_dataset\u001B[1;34m()\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mload_dataset\u001B[39m():\n\u001B[1;32m----> 6\u001B[0m     train_dataset \u001B[38;5;241m=\u001B[39m \u001B[43mh5py\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mFile\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mdatasets/train_catvnoncat.h5\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mr\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      7\u001B[0m     train_set_x_orig \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(train_dataset[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain_set_x\u001B[39m\u001B[38;5;124m\"\u001B[39m][:]) \u001B[38;5;66;03m# your train set features\u001B[39;00m\n\u001B[0;32m      8\u001B[0m     train_set_y_orig \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(train_dataset[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain_set_y\u001B[39m\u001B[38;5;124m\"\u001B[39m][:]) \u001B[38;5;66;03m# your train set labels\u001B[39;00m\n",
      "File \u001B[1;32mC:\\Users\\liyy\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\h5py\\_hl\\files.py:564\u001B[0m, in \u001B[0;36mFile.__init__\u001B[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001B[0m\n\u001B[0;32m    555\u001B[0m     fapl \u001B[38;5;241m=\u001B[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001B[0;32m    556\u001B[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001B[0;32m    557\u001B[0m                      alignment_threshold\u001B[38;5;241m=\u001B[39malignment_threshold,\n\u001B[0;32m    558\u001B[0m                      alignment_interval\u001B[38;5;241m=\u001B[39malignment_interval,\n\u001B[0;32m    559\u001B[0m                      meta_block_size\u001B[38;5;241m=\u001B[39mmeta_block_size,\n\u001B[0;32m    560\u001B[0m                      \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    561\u001B[0m     fcpl \u001B[38;5;241m=\u001B[39m make_fcpl(track_order\u001B[38;5;241m=\u001B[39mtrack_order, fs_strategy\u001B[38;5;241m=\u001B[39mfs_strategy,\n\u001B[0;32m    562\u001B[0m                      fs_persist\u001B[38;5;241m=\u001B[39mfs_persist, fs_threshold\u001B[38;5;241m=\u001B[39mfs_threshold,\n\u001B[0;32m    563\u001B[0m                      fs_page_size\u001B[38;5;241m=\u001B[39mfs_page_size)\n\u001B[1;32m--> 564\u001B[0m     fid \u001B[38;5;241m=\u001B[39m \u001B[43mmake_fid\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muserblock_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfapl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfcpl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mswmr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mswmr\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    566\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(libver, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[0;32m    567\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_libver \u001B[38;5;241m=\u001B[39m libver\n",
      "File \u001B[1;32mC:\\Users\\liyy\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\h5py\\_hl\\files.py:238\u001B[0m, in \u001B[0;36mmake_fid\u001B[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001B[0m\n\u001B[0;32m    236\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m swmr \u001B[38;5;129;01mand\u001B[39;00m swmr_support:\n\u001B[0;32m    237\u001B[0m         flags \u001B[38;5;241m|\u001B[39m\u001B[38;5;241m=\u001B[39m h5f\u001B[38;5;241m.\u001B[39mACC_SWMR_READ\n\u001B[1;32m--> 238\u001B[0m     fid \u001B[38;5;241m=\u001B[39m \u001B[43mh5f\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mflags\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfapl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfapl\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    239\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m mode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mr+\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m    240\u001B[0m     fid \u001B[38;5;241m=\u001B[39m h5f\u001B[38;5;241m.\u001B[39mopen(name, h5f\u001B[38;5;241m.\u001B[39mACC_RDWR, fapl\u001B[38;5;241m=\u001B[39mfapl)\n",
      "File \u001B[1;32mh5py\\\\_objects.pyx:54\u001B[0m, in \u001B[0;36mh5py._objects.with_phil.wrapper\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mh5py\\\\_objects.pyx:55\u001B[0m, in \u001B[0;36mh5py._objects.with_phil.wrapper\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mh5py\\\\h5f.pyx:102\u001B[0m, in \u001B[0;36mh5py.h5f.open\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] Unable to synchronously open file (unable to open file: name = 'datasets/train_catvnoncat.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们在数据集（训练和测试）的末尾添加了“_orig”，方便对它们进行预处理。\n",
    "\n",
    "预处理后，将得到train_set_x和test_set_x。（标签train_set_y和test_set_y不需要预处理）          \n",
    "\n",
    "train_set_x_orig和test_set_x_orig的每一行都是表示图像的数组。\n",
    "\n",
    "可以通过运行以下代码来可视化(你也可以随意更改索引值`index` 重新运行来查看其他图像）。"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T11:34:28.822104Z",
     "start_time": "2025-03-04T11:34:28.812973Z"
    }
   },
   "source": [
    "# Example of a picture\n",
    "index = 30\n",
    "plt.imshow(train_set_x_orig[index])\n",
    "print (\"y = \" + str(train_set_y[:, index]) + \", it's a '\" + classes[np.squeeze(train_set_y[:, index])].decode(\"utf-8\") +  \"' picture.\")"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_set_x_orig' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Example of a picture\u001B[39;00m\n\u001B[0;32m      2\u001B[0m index \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m30\u001B[39m\n\u001B[1;32m----> 3\u001B[0m plt\u001B[38;5;241m.\u001B[39mimshow(\u001B[43mtrain_set_x_orig\u001B[49m[index])\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my = \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(train_set_y[:, index]) \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m, it\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124ms a \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m classes[np\u001B[38;5;241m.\u001B[39msqueeze(train_set_y[:, index])]\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;241m+\u001B[39m  \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m picture.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'train_set_x_orig' is not defined"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 定义以下变量：** \n",
    "    - m_train (训练样本数量)\n",
    "    - m_test (测试样本数量)\n",
    "    - num_px (训练集的图片像素宽度)\n",
    "\n",
    "提示：`train_set_x_orig` 是一个 numpy数组，shape为(m_train, num_px, num_px, 3)，你可以通过`train_set_x_orig.shape[0]`来获取`m_train`  ."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-03-04T09:40:02.929611Z",
     "start_time": "2025-03-04T09:40:02.908584Z"
    }
   },
   "source": [
    "### START CODE HERE ### (≈ 3 lines of code)\n",
    "\n",
    "\n",
    "\n",
    "### END CODE HERE ###\n",
    "\n",
    "print (\"Number of training examples: m_train = \" + str(m_train))\n",
    "print (\"Number of testing examples: m_test = \" + str(m_test))\n",
    "print (\"Height/Width of each image: num_px = \" + str(num_px))\n",
    "print (\"Each image is of size: (\" + str(num_px) + \", \" + str(num_px) + \", 3)\")\n",
    "print (\"train_set_x shape: \" + str(train_set_x_orig.shape))\n",
    "print (\"train_set_y shape: \" + str(train_set_y.shape))\n",
    "print (\"test_set_x shape: \" + str(test_set_x_orig.shape))\n",
    "print (\"test_set_y shape: \" + str(test_set_y.shape))"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'm_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 7\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m### START CODE HERE ### (≈ 3 lines of code)\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \n\u001B[0;32m      3\u001B[0m \n\u001B[0;32m      4\u001B[0m \n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m### END CODE HERE ###\u001B[39;00m\n\u001B[1;32m----> 7\u001B[0m \u001B[38;5;28mprint\u001B[39m (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNumber of training examples: m_train = \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(\u001B[43mm_train\u001B[49m))\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28mprint\u001B[39m (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNumber of testing examples: m_test = \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(m_test))\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28mprint\u001B[39m (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mHeight/Width of each image: num_px = \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(num_px))\n",
      "\u001B[1;31mNameError\u001B[0m: name 'm_train' is not defined"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output：**\n",
    "<table style=\"width:15%\">\n",
    "  <tr>\n",
    "    <td>**m_train**</td>\n",
    "    <td> 209 </td> \n",
    "  </tr>\n",
    "  \n",
    "  <tr>\n",
    "    <td>**m_test**</td>\n",
    "    <td> 50 </td> \n",
    "  </tr>\n",
    "  \n",
    "  <tr>\n",
    "    <td>**num_px**</td>\n",
    "    <td> 64 </td> \n",
    "  </tr>\n",
    "  \n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了方便处理，我们需要把图像reshape到（num-px * num-px * 3，1）。\n",
    "\n",
    "这样以后，我们的训练\\测试数据集是一个numpy数组，其中每一列表示一个展平的图像，应有m_train\\m_test列。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** \n",
    "\n",
    "Reshape训练集train_set_x_flatten和测试集test_set_x_flatten， 让(num_px, num_px, 3)展平到 (num\\_px $*$ num\\_px $*$ 3, 1).\n",
    "\n",
    "\n",
    "提示：当你想把(a,b,c,d)形状的数组X展平到X_flatten(b$*$c$*$d, a)，也可以用: \n",
    "```python\n",
    "X_flatten = X.reshape(X.shape[0], -1).T      # X.T is the transpose of X\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the training and test examples\n",
    "\n",
    "### START CODE HERE ### (≈ 2 lines of code)\n",
    "\n",
    "\n",
    "# train_set_x_flatten = train_set_x_orig.reshape(-1, train_set_x_orig.shape[0])\n",
    "\n",
    "\n",
    "### END CODE HERE ###\n",
    "\n",
    "print (\"train_set_x_flatten shape: \" + str(train_set_x_flatten.shape))\n",
    "print (\"train_set_y shape: \" + str(train_set_y.shape))\n",
    "print (\"test_set_x_flatten shape: \" + str(test_set_x_flatten.shape))\n",
    "print (\"test_set_y shape: \" + str(test_set_y.shape))\n",
    "print (\"sanity check after reshaping: \" + str(train_set_x_flatten[0:5,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**: \n",
    "\n",
    "<table style=\"width:35%\">\n",
    "  <tr>\n",
    "    <td>**train_set_x_flatten shape**</td>\n",
    "    <td> (12288, 209)</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>**train_set_y shape**</td>\n",
    "    <td>(1, 209)</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>**test_set_x_flatten shape**</td>\n",
    "    <td>(12288, 50)</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>**test_set_y shape**</td>\n",
    "    <td>(1, 50)</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "  <td>**sanity check after reshaping**</td>\n",
    "  <td>[17 31 56 22 33]</td> \n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "图片的RGB像素值是由三个0到255之间的数字组成的向量。   \n",
    "\n",
    "机器学习中一个常见的预处理步骤是将数据集标准化，但对于图片数据集来说比较简单、方便，我们将数据集的每一行除以255（像素通道的最大值）就可以了。          \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_x = train_set_x_flatten/255.\n",
    "test_set_x = test_set_x_flatten/255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "**预处理数据集的常见步骤:**\n",
    "\n",
    "- 找出数据的shape (m_train, m_test, num_px, ...)\n",
    "- Reshape to (num_px \\* num_px \\* 3, 1)\n",
    "- 标准化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - 算法结构 ##\n",
    "            \n",
    "你将建立一个逻辑回归来区分猫和非猫。\n",
    "\n",
    "下图展示了为什么**逻辑回归实际上是一个非常简单的神经网络！**\n",
    "\n",
    "<img src=\"images/LogReg_kiank.png\" style=\"width:650px;height:400px;\">\n",
    "\n",
    "**逻辑回归算法的数学表达式**:\n",
    "\n",
    "For one example $x^{(i)}$:\n",
    "$$z^{(i)} = w^T x^{(i)} + b \\tag{1}$$\n",
    "$$\\hat{y}^{(i)} = a^{(i)} = sigmoid(z^{(i)})\\tag{2}$$ \n",
    "$$ \\mathcal{L}(a^{(i)}, y^{(i)}) =  - y^{(i)}  \\log(a^{(i)}) - (1-y^{(i)} )  \\log(1-a^{(i)})\\tag{3}$$\n",
    "\n",
    "对所有的样本来计算损失函数\n",
    "$$ J = \\frac{1}{m} \\sum_{i=1}^m \\mathcal{L}(a^{(i)}, y^{(i)})\\tag{6}$$\n",
    "\n",
    "**关键步骤**:\n",
    "\n",
    "-初始化模型参数              \n",
    "-最小化损失函数来训练、学习模型参数              \n",
    "-使用学习到的参数进行预测（在测试集上）              \n",
    "-分析结果并得出结论"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - 构建算法 ## \n",
    "\n",
    "1. 定义模型结构 \n",
    "2. 初始化参数\n",
    "3. 循环:\n",
    "    - 计算损失 (forward propagation)\n",
    "    - 计算梯度 (backward propagation)\n",
    "    - 更新参数 (gradient descent)\n",
    "\n",
    "整合以上步骤，便可以搭建 `model()`.\n",
    "\n",
    "### 4.1 - 函数帮助\n",
    "\n",
    "**Exercise**: \n",
    "\n",
    "用python实现函数 `sigmoid()`. \n",
    "\n",
    "要用 $sigmoid( w^T x + b) = \\frac{1}{1 + e^{-(w^T x + b)}}$ 来预测，可以使用np.exp()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: sigmoid\n",
    "\n",
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    Compute the sigmoid of z\n",
    "\n",
    "    Arguments:\n",
    "    z -- A scalar or numpy array of any size.\n",
    "\n",
    "    Return:\n",
    "    s -- sigmoid(z)\n",
    "    \"\"\"\n",
    "\n",
    "    ### START CODE HERE ### (≈ 1 line of code)\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print (\"sigmoid([0, 2]) = \" + str(sigmoid(np.array([0,2]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**: \n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <td>**sigmoid([0, 2])**</td>\n",
    "    <td> [ 0.5         0.88079708]</td> \n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 - 初始化参数\n",
    "\n",
    "**Exercise:** \n",
    "\n",
    "实现w和b的参数初始化，你必须把w初始化为一个全0向量。\n",
    "\n",
    "提示：可以使用numpy库中的函数np.zeros()。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: initialize_with_zeros\n",
    "\n",
    "def initialize_with_zeros(dim):\n",
    "    \"\"\"\n",
    "    This function creates a vector of zeros of shape (dim, 1) for w and initializes b to 0.\n",
    "    \n",
    "    Argument:\n",
    "    dim -- size of the w vector we want (or number of parameters in this case)\n",
    "    \n",
    "    Returns:\n",
    "    w -- initialized vector of shape (dim, 1)\n",
    "    b -- initialized scalar (corresponds to the bias)\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ### (≈ 1 line of code)\n",
    "   \n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    assert(w.shape == (dim, 1))     #条件为False时触发异常\n",
    "    assert(isinstance(b, float) or isinstance(b, int))\n",
    "    \n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 2\n",
    "w, b = initialize_with_zeros(dim)\n",
    "print (\"w = \" + str(w))\n",
    "print (\"b = \" + str(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**: \n",
    "\n",
    "\n",
    "<table style=\"width:15%\">\n",
    "    <tr>\n",
    "        <td>  ** w **  </td>\n",
    "        <td> [[ 0.]\n",
    " [ 0.]] </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>  ** b **  </td>\n",
    "        <td> 0 </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "对于本案例来说，w的shape应该为(num_px $\\times$ num_px $\\times$ 3, 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 - 正向与反向传播\n",
    "\n",
    "**Exercise:** \n",
    "\n",
    "完成函数 `propagate()` 来计算损失和梯度。\n",
    "\n",
    "**Hints**:\n",
    "\n",
    "前向:\n",
    "\n",
    "- $A = \\sigma(w^T X + b) = (a^{(0)}, a^{(1)}, ..., a^{(m-1)}, a^{(m)})$\n",
    "- $J = -\\frac{1}{m}\\sum_{i=1}^{m}y^{(i)}\\log(a^{(i)})+(1-y^{(i)})\\log(1-a^{(i)})$\n",
    "\n",
    "这两个公式你可能会用到: \n",
    "\n",
    "$$ \\frac{\\partial J}{\\partial w} = \\frac{1}{m}X(A-Y)^T\\tag{7}$$\n",
    "$$ \\frac{\\partial J}{\\partial b} = \\frac{1}{m} \\sum_{i=1}^m (a^{(i)}-y^{(i)})\\tag{8}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: propagate\n",
    "\n",
    "def propagate(w, b, X, Y):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n",
    "    b -- bias, a scalar\n",
    "    X -- data of size (num_px * num_px * 3, number of examples)\n",
    "    Y -- true \"label\" vector (containing 0 if non-cat, 1 if cat) of size (1, number of examples)\n",
    "\n",
    "    Return:\n",
    "    cost -- negative log-likelihood cost for logistic regression\n",
    "    dw -- gradient of the loss with respect to w, thus same shape as w\n",
    "    db -- gradient of the loss with respect to b, thus same shape as b\n",
    "    \n",
    "    Tips:\n",
    "    - Write your code step by step for the propagation. \n",
    "    可能会使用到：np.dot()，np.log()，np.sum()\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    \n",
    "    # FORWARD PROPAGATION (FROM X TO COST,define A and cost)\n",
    "    ### START CODE HERE ### (≈ 2 lines of code)\n",
    "    \n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # BACKWARD PROPAGATION (define dw and db)\n",
    "    ### START CODE HERE ### (≈ 2 lines of code)\n",
    "    \n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    assert(dw.shape == w.shape)\n",
    "    assert(db.dtype == float)\n",
    "    cost = np.squeeze(cost)\n",
    "    assert(cost.shape == ())\n",
    "    \n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "    \n",
    "    return grads, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, b, X, Y = np.array([[1],[2]]), 2, np.array([[1,2],[3,4]]), np.array([[1,0]])\n",
    "grads, cost = propagate(w, b, X, Y)\n",
    "print (\"dw = \" + str(grads[\"dw\"]))\n",
    "print (\"db = \" + str(grads[\"db\"]))\n",
    "print (\"cost = \" + str(cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "\n",
    "<table style=\"width:50%\">\n",
    "    <tr>\n",
    "        <td>  ** dw **  </td>\n",
    "        <td> [[ 0.99993216]\n",
    " [ 1.99980262]]</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>  ** db **  </td>\n",
    "        <td> 0.499935230625 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>  ** cost **  </td>\n",
    "        <td> 6.000064773192205</td>\n",
    "    </tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 - 优化\n",
    "现在你需要用梯度下降更新参数\n",
    "\n",
    "**Exercise:** \n",
    "\n",
    "完成优化函数`optimize()`,目标是通过最小化 $J$ 学习 $w$ 和 $b$ . \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: optimize\n",
    "\n",
    "def optimize(w, b, X, Y, num_iterations, learning_rate, print_cost = False):\n",
    "    \"\"\"\n",
    "    This function optimizes w and b by running a gradient descent algorithm\n",
    "    \n",
    "    Arguments:\n",
    "    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n",
    "    b -- bias, a scalar\n",
    "    X -- data of shape (num_px * num_px * 3, number of examples)\n",
    "    Y -- true \"label\" vector (containing 0 if non-cat, 1 if cat), of shape (1, number of examples)\n",
    "    num_iterations -- number of iterations of the optimization loop\n",
    "    learning_rate -- learning rate of the gradient descent update rule\n",
    "    print_cost -- True to print the loss every 100 steps\n",
    "    \n",
    "    Returns:\n",
    "    params -- dictionary containing the weights w and bias b\n",
    "    grads -- dictionary containing the gradients of the weights and bias with respect to the cost function\n",
    "    costs -- list of all the costs computed during the optimization, this will be used to plot the learning curve.\n",
    "    \n",
    "    Tips:\n",
    "    You basically need to write down two steps and iterate through them:\n",
    "        1) Calculate the cost and the gradient for the current parameters. Use propagate().\n",
    "        2) Update the parameters using gradient descent rule for w and b.\n",
    "    \"\"\"\n",
    "    \n",
    "    costs = []\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        \n",
    "        # Cost and gradient calculation (≈ 1-4 lines of code)\n",
    "        ### START CODE HERE ### (提取grads和cost)\n",
    "        \n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "        # Retrieve derivatives from grads\n",
    "        dw = grads[\"dw\"]\n",
    "        db = grads[\"db\"]\n",
    "        \n",
    "        # update rule (≈ 2 lines of code)\n",
    "        ### START CODE HERE ###（更新w和b）\n",
    "        \n",
    "        \n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "        # Record the costs\n",
    "        if i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "        \n",
    "        # Print the cost every 100 training examples\n",
    "        if print_cost and i % 100 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "    \n",
    "    params = {\"w\": w,\n",
    "              \"b\": b}\n",
    "    \n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "    \n",
    "    return params, grads, costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params, grads, costs = optimize(w, b, X, Y, num_iterations= 100, learning_rate = 0.009, print_cost = False)\n",
    "print (\"w = \" + str(params[\"w\"]))\n",
    "print (\"b = \" + str(params[\"b\"]))\n",
    "print (\"dw = \" + str(grads[\"dw\"]))\n",
    "print (\"db = \" + str(grads[\"db\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**: \n",
    "\n",
    "<table style=\"width:40%\">\n",
    "    <tr>\n",
    "       <td> **w** </td>\n",
    "       <td>[[ 0.1124579 ]\n",
    " [ 0.23106775]] </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "       <td> **b** </td>\n",
    "       <td> 1.55930492484 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "       <td> **dw** </td>\n",
    "       <td> [[ 0.90158428]\n",
    " [ 1.76250842]] </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "       <td> **db** </td>\n",
    "       <td> 0.430462071679 </td>\n",
    "    </tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** \n",
    "\n",
    "上一个函数将输出学习到的w和b。我们利用它们实现`predict()` 函数，在测试集上测试。\n",
    "\n",
    "计算步骤：\n",
    "\n",
    "1. 计算 $ Y prediction = A = \\sigma(w^T X + b)$\n",
    "\n",
    "2. 将结果转换成 0 (if activation <= 0.5) 或 1 (if activation > 0.5), 并将结果存入 `Y_prediction`. 你可以使用 `if`/`else` 语句"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: predict\n",
    "\n",
    "def predict(w, b, X):\n",
    "    '''\n",
    "    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n",
    "    \n",
    "    Arguments:\n",
    "    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n",
    "    b -- bias, a scalar\n",
    "    X -- data of size (num_px * num_px * 3, number of examples)\n",
    "    \n",
    "    Returns:\n",
    "    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n",
    "    '''\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    Y_prediction = np.zeros((1,m))\n",
    "    w = w.reshape(X.shape[0], 1)\n",
    "    \n",
    "    # Compute vector \"A\" predicting the probabilities of a cat being present in the picture\n",
    "    ### START CODE HERE ### (≈ 1 line of code)\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    for i in range(A.shape[1]):\n",
    "        \n",
    "        # Convert probabilities A[0,i] to actual predictions p[0,i]\n",
    "        ### START CODE HERE ### (≈ 4 lines of code)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        ### END CODE HERE ###\n",
    "    \n",
    "    assert(Y_prediction.shape == (1, m))\n",
    "    \n",
    "    return Y_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"predictions = \" + str(predict(w, b, X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**: \n",
    "\n",
    "<table style=\"width:30%\">\n",
    "    <tr>\n",
    "         <td>\n",
    "             **predictions**\n",
    "         </td>\n",
    "          <td>\n",
    "            [[ 1.  1.]]\n",
    "         </td>  \n",
    "   </tr>\n",
    "\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 - 整合所有的函数到model中 ##\n",
    "\n",
    "现在按照正确顺序，将所有前面部分中实现的函数组合在一起，构建整个模型。\n",
    "\n",
    "**Exercise 实现模型：** :\n",
    "    - Y_prediction 在测试集上的预测值\n",
    "    - Y_prediction_train 在训练集上的预测\n",
    "    - w, costs, grads 为 optimize() 的输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: model\n",
    "\n",
    "def model(X_train, Y_train, X_test, Y_test, num_iterations = 2000, learning_rate = 0.5, print_cost = False):\n",
    "    \"\"\"\n",
    "    Builds the logistic regression model by calling the function you've implemented previously\n",
    "    \n",
    "    Arguments:\n",
    "    X_train -- training set represented by a numpy array of shape (num_px * num_px * 3, m_train)\n",
    "    Y_train -- training labels represented by a numpy array (vector) of shape (1, m_train)\n",
    "    X_test -- test set represented by a numpy array of shape (num_px * num_px * 3, m_test)\n",
    "    Y_test -- test labels represented by a numpy array (vector) of shape (1, m_test)\n",
    "    num_iterations -- hyperparameter representing the number of iterations to optimize the parameters\n",
    "    learning_rate -- hyperparameter representing the learning rate used in the update rule of optimize()\n",
    "    print_cost -- Set to true to print the cost every 100 iterations\n",
    "    \n",
    "    Returns:\n",
    "    d -- dictionary containing information about the model.\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    \n",
    "    # initialize parameters（w and b） with zeros (≈ 1 line of code)\n",
    "    \n",
    "\n",
    "    # Gradient descent(use optimize function) (≈ 1 line of code)\n",
    "    \n",
    "    \n",
    "    # Retrieve parameters w and b from dictionary \"params\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Predict test/train set examples (≈ 2 lines of code)\n",
    "    \n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Print train/test Errors\n",
    "    print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_train - Y_train)) * 100))\n",
    "    print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_test - Y_test)) * 100))\n",
    "\n",
    "    \n",
    "    d = {\"costs\": costs,\n",
    "         \"Y_prediction_test\": Y_prediction_test, \n",
    "         \"Y_prediction_train\" : Y_prediction_train, \n",
    "         \"w\" : w, \n",
    "         \"b\" : b,\n",
    "         \"learning_rate\" : learning_rate,\n",
    "         \"num_iterations\": num_iterations}\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to train your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = model(train_set_x, train_set_y, test_set_x, test_set_y, num_iterations = 2000, learning_rate = 0.005, print_cost = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**: \n",
    "\n",
    "<table style=\"width:40%\"> \n",
    "    \n",
    "   <tr>\n",
    "        <td> **Train Accuracy**  </td> \n",
    "        <td> 99.04306220095694 % </td>\n",
    "    </tr>\n",
    "\n",
    "   <tr>\n",
    "        <td>**Test Accuracy** </td> \n",
    "        <td> 70.0 % </td>\n",
    "    </tr>\n",
    "</table> \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Comment**: \n",
    "\n",
    "训练精度接近100%，说明模型被训练的不错。测试误差为68%，因为我们使用的数据集很小，而且逻辑回归是一个线性分类器，所以对于这个简单的模型来说，这个结果已经不算太差了。\n",
    "\n",
    "如果想做的更好，下周你会学到一个更棒的分类器！              \n",
    "\n",
    "ps：可以看到，模型显然过拟合了。后面我们可以学习使用正则化等方式来优化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of a picture that was wrongly classified.\n",
    "index = 9\n",
    "plt.imshow(test_set_x[:,index].reshape((num_px, num_px, 3)))\n",
    "print (\"y = \" + str(test_set_y[0,index]) + \", you predicted that it is a \\\"\" + classes[int(d[\"Y_prediction_test\"][0,index])].decode(\"utf-8\") +  \"\\\" picture.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们也绘制一下损失函数和梯度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot learning curve (with costs)\n",
    "costs = np.squeeze(d['costs'])\n",
    "plt.plot(costs)\n",
    "plt.ylabel('cost')\n",
    "plt.xlabel('iterations (per hundreds)')\n",
    "plt.title(\"Learning rate =\" + str(d[\"learning_rate\"]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 - 进一步分析 (选做) ##\n",
    "\n",
    "我们来探索一下更多的学习率 $\\alpha$ 的可能性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Reminder**:\n",
    "为了使梯度下降起作用，你必须明智地选择学习率$\\alpha$。学习率决定了我们更新参数的速度。\n",
    "\n",
    "如果学习率太大，我们可能会“超调”最佳值。如果太小，我们将需要太多的迭代来收敛。\n",
    "\n",
    "下面，我们尝试使用不同的学习率，比较模型的学习曲线，你可以自己调整`learning_rates` 然后看看会发生什么。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = [0.01, 0.005, 0.001, 0.0005, 0.0001]\n",
    "models = {}\n",
    "for i in learning_rates:\n",
    "    print (\"learning rate is: \" + str(i))\n",
    "    models[str(i)] = model(train_set_x, train_set_y, test_set_x, test_set_y, num_iterations = 1500, learning_rate = i, print_cost = False)\n",
    "    print ('\\n' + \"-------------------------------------------------------\" + '\\n')\n",
    "\n",
    "for i in learning_rates:\n",
    "    plt.plot(np.squeeze(models[str(i)][\"costs\"]), label= str(models[str(i)][\"learning_rate\"]))\n",
    "\n",
    "plt.ylabel('cost')\n",
    "plt.xlabel('iterations')\n",
    "\n",
    "legend = plt.legend(loc='upper center', shadow=True)\n",
    "frame = legend.get_frame()\n",
    "frame.set_facecolor('0.90')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 7 - 使用自己的图像来测试  ##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_image = \"cat_in_iran.jpg\"\n",
    "fname = \"images/\" + my_image\n",
    "image = np.array(cv2.imread(fname))\n",
    "print(image.shape)\n",
    "my_image = cv2.resize(image, (num_px,num_px)) #变成64*64*3\n",
    "my_image = my_image.reshape(my_image.shape[0]*my_image.shape[1]*my_image.shape[2],1)\n",
    "my_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "## START CODE HERE ## (PUT YOUR IMAGE NAME) \n",
    "my_image = \"cat_in_iran.jpg\"   # change this to the name of your image file \n",
    "## END CODE HERE ##\n",
    "\n",
    "# We preprocess the image to fit your algorithm.\n",
    "fname = \"images/\" + my_image\n",
    "\n",
    "image = np.array(cv2.imread(fname))\n",
    "my_image = cv2.resize(image, (num_px,num_px)) \n",
    "my_image = my_image.reshape(my_image.shape[0]*my_image.shape[1]*my_image.shape[2],1)\n",
    "\n",
    "my_predicted_image = predict(d[\"w\"], d[\"b\"], my_image)\n",
    "\n",
    "plt.imshow(image)\n",
    "print(\"y = \" + str(np.squeeze(my_predicted_image)) + \", your algorithm predicts a \\\"\" + classes[int(np.squeeze(my_predicted_image)),].decode(\"utf-8\") +  \"\\\" picture.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bibliography:\n",
    "- http://www.wildml.com/2015/09/implementing-a-neural-network-from-scratch/\n",
    "- https://stats.stackexchange.com/questions/211436/why-do-we-normalize-images-by-subtracting-the-datasets-image-mean-and-not-the-c"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "neural-networks-deep-learning",
   "graded_item_id": "XaIWT",
   "launcher_item_id": "zAgPl"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
