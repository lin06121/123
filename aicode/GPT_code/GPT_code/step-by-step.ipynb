{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b197111f3dd1d21d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T04:23:38.643505Z",
     "start_time": "2024-02-09T04:23:10.263131Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import tiktoken\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adec81e8b065abf4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T04:23:51.966821Z",
     "start_time": "2024-02-09T04:23:51.948834Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2392d1a2830>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 4  # How many batches per training step\n",
    "context_length = 16  # Length of the token chunk each batch\n",
    "d_model = 64  # The vector size of the token embeddings\n",
    "num_layers = 8  # Number of transformer blocks\n",
    "num_heads = 4  # Number of heads in Multi-head attention # 我们的代码中通过 d_model / num_heads = 来获取 head_size\n",
    "learning_rate = 1e-3  # 0.001\n",
    "dropout = 0.1 # Dropout rate\n",
    "max_iters = 500  # Total of training iterations\n",
    "eval_interval = 50  # How often to evaluate the model \n",
    "eval_iters = 20  # How many iterations to average the loss over when evaluating the model\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'  # Instead of using the cpu, we'll use the GPU if it's available.\n",
    "\n",
    "TORCH_SEED = 1337\n",
    "torch.manual_seed(TORCH_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T04:23:53.539657Z",
     "start_time": "2024-02-09T04:23:53.516333Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chapter 1: Building Rapport and Capturing Attention\n",
      "Subpoint: Understanding the Importance of Buildi\n"
     ]
    }
   ],
   "source": [
    "with open('./sales_textbook.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "print(text[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78542973",
   "metadata": {},
   "source": [
    "### tokenizer 分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8eb984bfcb7a06b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T04:24:44.270382Z",
     "start_time": "2024-02-09T04:24:44.140668Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized text size: 77919\n",
      "The maximum value in the tokenized text is: 100069\n"
     ]
    }
   ],
   "source": [
    "# Using TikToken to tokenize the source text\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "tokenized_text = encoding.encode(text)\n",
    "tokenized_text = torch.tensor(tokenized_text, dtype=torch.long, device=device) # Convert tokens into a tensor\n",
    "max_token_value = tokenized_text.max().item() # the maximum index value in our vocabulary\n",
    "\n",
    "print(f\"Tokenized text size: {len(tokenized_text)}\")\n",
    "print(f\"The maximum value in the tokenized text is: {max_token_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bd965d977d210d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T04:24:52.889469Z",
     "start_time": "2024-02-09T04:24:52.878327Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70127, 7792)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split train and validation\n",
    "split_idx = int(len(tokenized_text) * 0.9)\n",
    "train_data = tokenized_text[:split_idx]\n",
    "val_data = tokenized_text[split_idx:]\n",
    "len(train_data), len(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd4d699c1f25bbe6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T04:25:08.155569Z",
     "start_time": "2024-02-09T04:25:08.138702Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([35754, 55550, 63572,  1447])\n",
      "torch.Size([4, 16]) torch.Size([4, 16])\n",
      "tensor([[  279,  6763,  1920,    13,   578,  5845,   311, 13750, 19570,   279,\n",
      "           907,   323,  7720,   315,  1057,  3956],\n",
      "        [ 3495, 14955,    11,   477,  5064, 23146,   430,  9788,   279, 66732,\n",
      "           315,   701, 10209,    13,  3296, 32644],\n",
      "        [38769, 10742,    11, 20958,   264,  6928, 19451,    11, 11125, 64784,\n",
      "            11,   323, 56501, 54111,   439,  6975],\n",
      "        [43496,   872,  8830,   719,  1101,  3727,   279,  6130,  2733,  6755,\n",
      "           323, 16365,   627, 29831, 19682,  5900]], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([' the',\n",
       "  ' sales',\n",
       "  ' process',\n",
       "  '.',\n",
       "  ' The',\n",
       "  ' ability',\n",
       "  ' to',\n",
       "  ' effectively',\n",
       "  ' communicate',\n",
       "  ' the',\n",
       "  ' value',\n",
       "  ' and',\n",
       "  ' benefits',\n",
       "  ' of',\n",
       "  ' our',\n",
       "  ' products'],\n",
       " [' sales',\n",
       "  ' process',\n",
       "  '.',\n",
       "  ' The',\n",
       "  ' ability',\n",
       "  ' to',\n",
       "  ' effectively',\n",
       "  ' communicate',\n",
       "  ' the',\n",
       "  ' value',\n",
       "  ' and',\n",
       "  ' benefits',\n",
       "  ' of',\n",
       "  ' our',\n",
       "  ' products',\n",
       "  ' or'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare data for training batch\n",
    "data = train_data\n",
    "idxs = torch.randint(low=0, high=len(data) - context_length, size=(batch_size,))\n",
    "print(idxs)\n",
    "x_batch = torch.stack([data[idx:idx + context_length] for idx in idxs])\n",
    "y_batch = torch.stack([data[idx + 1:idx + context_length + 1] for idx in idxs])\n",
    "print(x_batch.shape, x_batch.shape)\n",
    "print(x_batch.data)\n",
    "\n",
    "[encoding.decode([i]) for i in x_batch[0]],[encoding.decode([i]) for i in y_batch[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e96ee8f724daac71",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T04:25:43.766159Z",
     "start_time": "2024-02-09T04:25:43.748077Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our batches:\n",
      "       0      1     2      3     4      5      6      7      8      9    10     11     12     13     14     15\n",
      "0    279   6763  1920     13   578   5845    311  13750  19570    279  907    323   7720    315   1057   3956\n",
      "1   3495  14955    11    477  5064  23146    430   9788    279  66732  315    701  10209     13   3296  32644\n",
      "2  38769  10742    11  20958   264   6928  19451     11  11125  64784   11    323  56501  54111    439   6975\n",
      "3  43496    872  8830    719  1101   3727    279   6130   2733   6755  323  16365    627  29831  19682   5900\n"
     ]
    }
   ],
   "source": [
    "# Illustration purpose\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "print(\"Our batches:\\n\", pd.DataFrame(x_batch.detach().cpu().numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a79c945",
   "metadata": {},
   "source": [
    "### Embedding 词向量嵌入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ade5a79e8c689ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T04:25:48.830907Z",
     "start_time": "2024-02-09T04:25:48.749815Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token Embedding Look-up table:  Embedding(100070, 64)\n"
     ]
    }
   ],
   "source": [
    "# Define Token Embedding look-up table\n",
    "token_embedding_lookup_table = nn.Embedding(max_token_value+1, d_model).to(device) #gpt3 使用的是50257 * 12288\n",
    "print(\"Token Embedding Look-up table: \", token_embedding_lookup_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62c03d62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(907, device='cuda:0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[61650]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73e5e010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100070, 64])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pd.set_option('expand_frame_repr', True)\n",
    "pd.DataFrame(_.detach().cpu().numpy())\n",
    "token_embedding_lookup_table.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86aa314dc5f6a76e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T04:25:54.090804Z",
     "start_time": "2024-02-09T04:25:54.057773Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.399742</td>\n",
       "      <td>-1.206918</td>\n",
       "      <td>0.327990</td>\n",
       "      <td>-0.251130</td>\n",
       "      <td>0.531874</td>\n",
       "      <td>-0.248193</td>\n",
       "      <td>0.351938</td>\n",
       "      <td>-0.389238</td>\n",
       "      <td>0.129977</td>\n",
       "      <td>-1.207580</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.547752</td>\n",
       "      <td>1.515671</td>\n",
       "      <td>1.223743</td>\n",
       "      <td>0.833670</td>\n",
       "      <td>-0.404194</td>\n",
       "      <td>0.563555</td>\n",
       "      <td>0.591292</td>\n",
       "      <td>-0.724745</td>\n",
       "      <td>1.670105</td>\n",
       "      <td>-0.241721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.566486</td>\n",
       "      <td>-1.102276</td>\n",
       "      <td>1.712332</td>\n",
       "      <td>-0.354509</td>\n",
       "      <td>0.550577</td>\n",
       "      <td>-0.707943</td>\n",
       "      <td>-0.743899</td>\n",
       "      <td>0.757765</td>\n",
       "      <td>0.018193</td>\n",
       "      <td>1.392380</td>\n",
       "      <td>...</td>\n",
       "      <td>0.873562</td>\n",
       "      <td>1.226714</td>\n",
       "      <td>0.794431</td>\n",
       "      <td>0.598629</td>\n",
       "      <td>0.884421</td>\n",
       "      <td>0.032520</td>\n",
       "      <td>1.353617</td>\n",
       "      <td>0.059697</td>\n",
       "      <td>1.172510</td>\n",
       "      <td>0.527427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.426478</td>\n",
       "      <td>1.717362</td>\n",
       "      <td>-0.343810</td>\n",
       "      <td>-0.917124</td>\n",
       "      <td>-0.273610</td>\n",
       "      <td>0.695366</td>\n",
       "      <td>-0.849842</td>\n",
       "      <td>-1.301135</td>\n",
       "      <td>-0.162554</td>\n",
       "      <td>-0.252810</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.934960</td>\n",
       "      <td>1.145729</td>\n",
       "      <td>-1.914150</td>\n",
       "      <td>-0.447346</td>\n",
       "      <td>0.597272</td>\n",
       "      <td>1.673483</td>\n",
       "      <td>-1.969475</td>\n",
       "      <td>0.397835</td>\n",
       "      <td>-0.438475</td>\n",
       "      <td>-0.562923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.709939</td>\n",
       "      <td>1.369311</td>\n",
       "      <td>-0.707588</td>\n",
       "      <td>1.538689</td>\n",
       "      <td>-2.110915</td>\n",
       "      <td>0.441344</td>\n",
       "      <td>-0.005807</td>\n",
       "      <td>0.171597</td>\n",
       "      <td>-0.296632</td>\n",
       "      <td>0.207320</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071533</td>\n",
       "      <td>-0.735549</td>\n",
       "      <td>0.069967</td>\n",
       "      <td>-2.744750</td>\n",
       "      <td>1.087368</td>\n",
       "      <td>-0.997812</td>\n",
       "      <td>0.714992</td>\n",
       "      <td>-1.357311</td>\n",
       "      <td>1.603957</td>\n",
       "      <td>0.920290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.963246</td>\n",
       "      <td>0.298927</td>\n",
       "      <td>0.131364</td>\n",
       "      <td>0.082995</td>\n",
       "      <td>0.153765</td>\n",
       "      <td>-0.821641</td>\n",
       "      <td>-1.220109</td>\n",
       "      <td>-1.088038</td>\n",
       "      <td>1.535371</td>\n",
       "      <td>1.829628</td>\n",
       "      <td>...</td>\n",
       "      <td>0.531913</td>\n",
       "      <td>-0.567854</td>\n",
       "      <td>-2.390947</td>\n",
       "      <td>-0.086596</td>\n",
       "      <td>0.066017</td>\n",
       "      <td>0.655226</td>\n",
       "      <td>0.624369</td>\n",
       "      <td>-0.763375</td>\n",
       "      <td>-0.692774</td>\n",
       "      <td>-0.007724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.811149</td>\n",
       "      <td>0.435134</td>\n",
       "      <td>1.131030</td>\n",
       "      <td>0.816734</td>\n",
       "      <td>-1.013971</td>\n",
       "      <td>-0.052429</td>\n",
       "      <td>-0.527541</td>\n",
       "      <td>-0.710573</td>\n",
       "      <td>-0.163887</td>\n",
       "      <td>-1.343154</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046995</td>\n",
       "      <td>-1.201052</td>\n",
       "      <td>-0.927833</td>\n",
       "      <td>0.322523</td>\n",
       "      <td>0.586139</td>\n",
       "      <td>0.108184</td>\n",
       "      <td>-1.653296</td>\n",
       "      <td>1.918813</td>\n",
       "      <td>0.941642</td>\n",
       "      <td>0.584330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.317549</td>\n",
       "      <td>2.106441</td>\n",
       "      <td>-0.092210</td>\n",
       "      <td>0.636316</td>\n",
       "      <td>-0.912476</td>\n",
       "      <td>-1.975633</td>\n",
       "      <td>-0.068806</td>\n",
       "      <td>0.201157</td>\n",
       "      <td>0.333519</td>\n",
       "      <td>0.151939</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200116</td>\n",
       "      <td>0.051824</td>\n",
       "      <td>1.304806</td>\n",
       "      <td>0.517675</td>\n",
       "      <td>0.049345</td>\n",
       "      <td>0.044632</td>\n",
       "      <td>1.346794</td>\n",
       "      <td>-0.321390</td>\n",
       "      <td>-0.478787</td>\n",
       "      <td>-0.166920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-2.025703</td>\n",
       "      <td>1.256391</td>\n",
       "      <td>-0.318619</td>\n",
       "      <td>1.432163</td>\n",
       "      <td>1.644837</td>\n",
       "      <td>-1.910154</td>\n",
       "      <td>-1.001209</td>\n",
       "      <td>-0.976038</td>\n",
       "      <td>1.502204</td>\n",
       "      <td>0.841974</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.339570</td>\n",
       "      <td>0.190785</td>\n",
       "      <td>-0.055200</td>\n",
       "      <td>2.281739</td>\n",
       "      <td>-0.417175</td>\n",
       "      <td>-0.801704</td>\n",
       "      <td>-1.393716</td>\n",
       "      <td>1.863095</td>\n",
       "      <td>-0.393567</td>\n",
       "      <td>-0.131746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.906978</td>\n",
       "      <td>0.092020</td>\n",
       "      <td>-0.785242</td>\n",
       "      <td>0.609121</td>\n",
       "      <td>-0.790180</td>\n",
       "      <td>-0.026004</td>\n",
       "      <td>-1.156866</td>\n",
       "      <td>0.398455</td>\n",
       "      <td>-0.455395</td>\n",
       "      <td>-0.251288</td>\n",
       "      <td>...</td>\n",
       "      <td>3.363073</td>\n",
       "      <td>-0.796739</td>\n",
       "      <td>1.757077</td>\n",
       "      <td>1.526690</td>\n",
       "      <td>-0.654219</td>\n",
       "      <td>1.660685</td>\n",
       "      <td>0.965431</td>\n",
       "      <td>0.618787</td>\n",
       "      <td>1.662946</td>\n",
       "      <td>1.768386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.399742</td>\n",
       "      <td>-1.206918</td>\n",
       "      <td>0.327990</td>\n",
       "      <td>-0.251130</td>\n",
       "      <td>0.531874</td>\n",
       "      <td>-0.248193</td>\n",
       "      <td>0.351938</td>\n",
       "      <td>-0.389238</td>\n",
       "      <td>0.129977</td>\n",
       "      <td>-1.207580</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.547752</td>\n",
       "      <td>1.515671</td>\n",
       "      <td>1.223743</td>\n",
       "      <td>0.833670</td>\n",
       "      <td>-0.404194</td>\n",
       "      <td>0.563555</td>\n",
       "      <td>0.591292</td>\n",
       "      <td>-0.724745</td>\n",
       "      <td>1.670105</td>\n",
       "      <td>-0.241721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.370826</td>\n",
       "      <td>0.272521</td>\n",
       "      <td>-1.915345</td>\n",
       "      <td>0.032303</td>\n",
       "      <td>0.017929</td>\n",
       "      <td>-1.451397</td>\n",
       "      <td>-1.632907</td>\n",
       "      <td>-1.165714</td>\n",
       "      <td>2.069243</td>\n",
       "      <td>0.550959</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.475737</td>\n",
       "      <td>0.216844</td>\n",
       "      <td>0.722587</td>\n",
       "      <td>1.340471</td>\n",
       "      <td>-0.709199</td>\n",
       "      <td>1.097342</td>\n",
       "      <td>0.231425</td>\n",
       "      <td>0.104482</td>\n",
       "      <td>-1.583871</td>\n",
       "      <td>1.481635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.030617</td>\n",
       "      <td>0.305096</td>\n",
       "      <td>-0.199683</td>\n",
       "      <td>1.021860</td>\n",
       "      <td>-0.044290</td>\n",
       "      <td>1.731110</td>\n",
       "      <td>-1.489611</td>\n",
       "      <td>0.928623</td>\n",
       "      <td>-0.587382</td>\n",
       "      <td>-1.500504</td>\n",
       "      <td>...</td>\n",
       "      <td>0.303483</td>\n",
       "      <td>-0.402739</td>\n",
       "      <td>0.042445</td>\n",
       "      <td>-0.872444</td>\n",
       "      <td>1.356491</td>\n",
       "      <td>1.417310</td>\n",
       "      <td>-1.436294</td>\n",
       "      <td>-0.745807</td>\n",
       "      <td>-0.242414</td>\n",
       "      <td>-0.457403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.927026</td>\n",
       "      <td>0.017112</td>\n",
       "      <td>-0.874911</td>\n",
       "      <td>1.184732</td>\n",
       "      <td>0.727968</td>\n",
       "      <td>-0.564862</td>\n",
       "      <td>-1.850788</td>\n",
       "      <td>0.852115</td>\n",
       "      <td>-0.866277</td>\n",
       "      <td>-1.235445</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.060539</td>\n",
       "      <td>0.198801</td>\n",
       "      <td>0.542944</td>\n",
       "      <td>-0.405061</td>\n",
       "      <td>0.361515</td>\n",
       "      <td>1.217013</td>\n",
       "      <td>-0.568322</td>\n",
       "      <td>1.032799</td>\n",
       "      <td>0.174048</td>\n",
       "      <td>1.400139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.625287</td>\n",
       "      <td>-1.128724</td>\n",
       "      <td>-2.476117</td>\n",
       "      <td>0.281622</td>\n",
       "      <td>0.046729</td>\n",
       "      <td>0.833730</td>\n",
       "      <td>-0.771643</td>\n",
       "      <td>-0.884734</td>\n",
       "      <td>0.910253</td>\n",
       "      <td>0.600033</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.394152</td>\n",
       "      <td>-0.798159</td>\n",
       "      <td>-0.969717</td>\n",
       "      <td>0.399133</td>\n",
       "      <td>-0.768250</td>\n",
       "      <td>0.607608</td>\n",
       "      <td>-1.891320</td>\n",
       "      <td>1.642382</td>\n",
       "      <td>-0.156069</td>\n",
       "      <td>-0.930427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.998070</td>\n",
       "      <td>1.024137</td>\n",
       "      <td>0.206201</td>\n",
       "      <td>-2.287179</td>\n",
       "      <td>-0.003692</td>\n",
       "      <td>0.207054</td>\n",
       "      <td>0.138208</td>\n",
       "      <td>-0.992636</td>\n",
       "      <td>0.491568</td>\n",
       "      <td>0.573276</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146838</td>\n",
       "      <td>0.273048</td>\n",
       "      <td>0.306777</td>\n",
       "      <td>-1.205792</td>\n",
       "      <td>-0.802286</td>\n",
       "      <td>-0.817414</td>\n",
       "      <td>-0.991609</td>\n",
       "      <td>0.227736</td>\n",
       "      <td>0.581187</td>\n",
       "      <td>0.285422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.512090</td>\n",
       "      <td>-0.403476</td>\n",
       "      <td>-1.283820</td>\n",
       "      <td>-1.035253</td>\n",
       "      <td>0.385313</td>\n",
       "      <td>0.251786</td>\n",
       "      <td>1.729430</td>\n",
       "      <td>1.389589</td>\n",
       "      <td>0.326549</td>\n",
       "      <td>-0.448694</td>\n",
       "      <td>...</td>\n",
       "      <td>1.361415</td>\n",
       "      <td>1.225376</td>\n",
       "      <td>-0.196476</td>\n",
       "      <td>-1.841317</td>\n",
       "      <td>-0.838676</td>\n",
       "      <td>-0.372250</td>\n",
       "      <td>0.113748</td>\n",
       "      <td>-0.636791</td>\n",
       "      <td>0.750731</td>\n",
       "      <td>0.664510</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6   \\\n",
       "0   1.399742 -1.206918  0.327990 -0.251130  0.531874 -0.248193  0.351938   \n",
       "1   0.566486 -1.102276  1.712332 -0.354509  0.550577 -0.707943 -0.743899   \n",
       "2  -0.426478  1.717362 -0.343810 -0.917124 -0.273610  0.695366 -0.849842   \n",
       "3   0.709939  1.369311 -0.707588  1.538689 -2.110915  0.441344 -0.005807   \n",
       "4  -1.963246  0.298927  0.131364  0.082995  0.153765 -0.821641 -1.220109   \n",
       "5   0.811149  0.435134  1.131030  0.816734 -1.013971 -0.052429 -0.527541   \n",
       "6   0.317549  2.106441 -0.092210  0.636316 -0.912476 -1.975633 -0.068806   \n",
       "7  -2.025703  1.256391 -0.318619  1.432163  1.644837 -1.910154 -1.001209   \n",
       "8   2.906978  0.092020 -0.785242  0.609121 -0.790180 -0.026004 -1.156866   \n",
       "9   1.399742 -1.206918  0.327990 -0.251130  0.531874 -0.248193  0.351938   \n",
       "10  0.370826  0.272521 -1.915345  0.032303  0.017929 -1.451397 -1.632907   \n",
       "11 -0.030617  0.305096 -0.199683  1.021860 -0.044290  1.731110 -1.489611   \n",
       "12 -0.927026  0.017112 -0.874911  1.184732  0.727968 -0.564862 -1.850788   \n",
       "13  0.625287 -1.128724 -2.476117  0.281622  0.046729  0.833730 -0.771643   \n",
       "14 -0.998070  1.024137  0.206201 -2.287179 -0.003692  0.207054  0.138208   \n",
       "15  0.512090 -0.403476 -1.283820 -1.035253  0.385313  0.251786  1.729430   \n",
       "\n",
       "          7         8         9   ...        54        55        56        57  \\\n",
       "0  -0.389238  0.129977 -1.207580  ... -0.547752  1.515671  1.223743  0.833670   \n",
       "1   0.757765  0.018193  1.392380  ...  0.873562  1.226714  0.794431  0.598629   \n",
       "2  -1.301135 -0.162554 -0.252810  ... -0.934960  1.145729 -1.914150 -0.447346   \n",
       "3   0.171597 -0.296632  0.207320  ...  0.071533 -0.735549  0.069967 -2.744750   \n",
       "4  -1.088038  1.535371  1.829628  ...  0.531913 -0.567854 -2.390947 -0.086596   \n",
       "5  -0.710573 -0.163887 -1.343154  ... -0.046995 -1.201052 -0.927833  0.322523   \n",
       "6   0.201157  0.333519  0.151939  ...  0.200116  0.051824  1.304806  0.517675   \n",
       "7  -0.976038  1.502204  0.841974  ... -2.339570  0.190785 -0.055200  2.281739   \n",
       "8   0.398455 -0.455395 -0.251288  ...  3.363073 -0.796739  1.757077  1.526690   \n",
       "9  -0.389238  0.129977 -1.207580  ... -0.547752  1.515671  1.223743  0.833670   \n",
       "10 -1.165714  2.069243  0.550959  ... -1.475737  0.216844  0.722587  1.340471   \n",
       "11  0.928623 -0.587382 -1.500504  ...  0.303483 -0.402739  0.042445 -0.872444   \n",
       "12  0.852115 -0.866277 -1.235445  ... -0.060539  0.198801  0.542944 -0.405061   \n",
       "13 -0.884734  0.910253  0.600033  ... -2.394152 -0.798159 -0.969717  0.399133   \n",
       "14 -0.992636  0.491568  0.573276  ...  0.146838  0.273048  0.306777 -1.205792   \n",
       "15  1.389589  0.326549 -0.448694  ...  1.361415  1.225376 -0.196476 -1.841317   \n",
       "\n",
       "          58        59        60        61        62        63  \n",
       "0  -0.404194  0.563555  0.591292 -0.724745  1.670105 -0.241721  \n",
       "1   0.884421  0.032520  1.353617  0.059697  1.172510  0.527427  \n",
       "2   0.597272  1.673483 -1.969475  0.397835 -0.438475 -0.562923  \n",
       "3   1.087368 -0.997812  0.714992 -1.357311  1.603957  0.920290  \n",
       "4   0.066017  0.655226  0.624369 -0.763375 -0.692774 -0.007724  \n",
       "5   0.586139  0.108184 -1.653296  1.918813  0.941642  0.584330  \n",
       "6   0.049345  0.044632  1.346794 -0.321390 -0.478787 -0.166920  \n",
       "7  -0.417175 -0.801704 -1.393716  1.863095 -0.393567 -0.131746  \n",
       "8  -0.654219  1.660685  0.965431  0.618787  1.662946  1.768386  \n",
       "9  -0.404194  0.563555  0.591292 -0.724745  1.670105 -0.241721  \n",
       "10 -0.709199  1.097342  0.231425  0.104482 -1.583871  1.481635  \n",
       "11  1.356491  1.417310 -1.436294 -0.745807 -0.242414 -0.457403  \n",
       "12  0.361515  1.217013 -0.568322  1.032799  0.174048  1.400139  \n",
       "13 -0.768250  0.607608 -1.891320  1.642382 -0.156069 -0.930427  \n",
       "14 -0.802286 -0.817414 -0.991609  0.227736  0.581187  0.285422  \n",
       "15 -0.838676 -0.372250  0.113748 -0.636791  0.750731  0.664510  \n",
       "\n",
       "[16 rows x 64 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get x and y embedding\n",
    "x_batch_embedding = token_embedding_lookup_table(x_batch.detach().to(device)) # [4, 16, 64] [batch_size, context_length, d_model]\n",
    "y_batch_embedding = token_embedding_lookup_table(y_batch.detach().to(device))\n",
    "\n",
    "x_batch_embedding.shape, y_batch_embedding.shape\n",
    "pd.DataFrame(x_batch_embedding[0].detach().cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ccb0f3",
   "metadata": {},
   "source": [
    "### 位置编码 Position Encoding PE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17f145bd89a13b23",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T04:26:57.181192Z",
     "start_time": "2024-02-09T04:26:57.135243Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Position Encoding Look-up Table:  torch.Size([4, 16, 64])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.841471</td>\n",
       "      <td>0.540302</td>\n",
       "      <td>0.681561</td>\n",
       "      <td>0.731761</td>\n",
       "      <td>0.533168</td>\n",
       "      <td>0.846009</td>\n",
       "      <td>0.409309</td>\n",
       "      <td>0.912396</td>\n",
       "      <td>0.310984</td>\n",
       "      <td>0.950415</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000422</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.909297</td>\n",
       "      <td>-0.416147</td>\n",
       "      <td>0.997480</td>\n",
       "      <td>0.070948</td>\n",
       "      <td>0.902131</td>\n",
       "      <td>0.431463</td>\n",
       "      <td>0.746903</td>\n",
       "      <td>0.664932</td>\n",
       "      <td>0.591127</td>\n",
       "      <td>0.806578</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000843</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000474</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000356</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.141120</td>\n",
       "      <td>-0.989992</td>\n",
       "      <td>0.778273</td>\n",
       "      <td>-0.627927</td>\n",
       "      <td>0.993253</td>\n",
       "      <td>-0.115966</td>\n",
       "      <td>0.953634</td>\n",
       "      <td>0.300967</td>\n",
       "      <td>0.812649</td>\n",
       "      <td>0.582754</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001265</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.000949</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000711</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000533</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.756802</td>\n",
       "      <td>-0.653644</td>\n",
       "      <td>0.141539</td>\n",
       "      <td>-0.989933</td>\n",
       "      <td>0.778472</td>\n",
       "      <td>-0.627680</td>\n",
       "      <td>0.993281</td>\n",
       "      <td>-0.115730</td>\n",
       "      <td>0.953581</td>\n",
       "      <td>0.301137</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001687</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.001265</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.000949</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000711</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000533</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.958924</td>\n",
       "      <td>0.283662</td>\n",
       "      <td>-0.571127</td>\n",
       "      <td>-0.820862</td>\n",
       "      <td>0.323935</td>\n",
       "      <td>-0.946079</td>\n",
       "      <td>0.858896</td>\n",
       "      <td>-0.512150</td>\n",
       "      <td>0.999947</td>\n",
       "      <td>-0.010342</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002108</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.001581</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.001186</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.000889</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.279415</td>\n",
       "      <td>0.960170</td>\n",
       "      <td>-0.977396</td>\n",
       "      <td>-0.211416</td>\n",
       "      <td>-0.230368</td>\n",
       "      <td>-0.973104</td>\n",
       "      <td>0.574026</td>\n",
       "      <td>-0.818837</td>\n",
       "      <td>0.947148</td>\n",
       "      <td>-0.320796</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002530</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.001897</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.001423</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.001067</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.656987</td>\n",
       "      <td>0.753902</td>\n",
       "      <td>-0.859313</td>\n",
       "      <td>0.511449</td>\n",
       "      <td>-0.713721</td>\n",
       "      <td>-0.700430</td>\n",
       "      <td>0.188581</td>\n",
       "      <td>-0.982058</td>\n",
       "      <td>0.800422</td>\n",
       "      <td>-0.599437</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002952</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.002214</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.001660</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.001245</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.000933</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.989358</td>\n",
       "      <td>-0.145500</td>\n",
       "      <td>-0.280228</td>\n",
       "      <td>0.959933</td>\n",
       "      <td>-0.977262</td>\n",
       "      <td>-0.212036</td>\n",
       "      <td>-0.229904</td>\n",
       "      <td>-0.973213</td>\n",
       "      <td>0.574318</td>\n",
       "      <td>-0.818632</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003374</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.002530</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.001897</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.001423</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.001067</td>\n",
       "      <td>0.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.412118</td>\n",
       "      <td>-0.911130</td>\n",
       "      <td>0.449194</td>\n",
       "      <td>0.893434</td>\n",
       "      <td>-0.939824</td>\n",
       "      <td>0.341660</td>\n",
       "      <td>-0.608108</td>\n",
       "      <td>-0.793854</td>\n",
       "      <td>0.291259</td>\n",
       "      <td>-0.956644</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003795</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>0.002846</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.002134</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.544021</td>\n",
       "      <td>-0.839072</td>\n",
       "      <td>0.937633</td>\n",
       "      <td>0.347628</td>\n",
       "      <td>-0.612937</td>\n",
       "      <td>0.790132</td>\n",
       "      <td>-0.879767</td>\n",
       "      <td>-0.475405</td>\n",
       "      <td>-0.020684</td>\n",
       "      <td>-0.999786</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004217</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.003162</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.002371</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.001778</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.001334</td>\n",
       "      <td>0.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.999990</td>\n",
       "      <td>0.004426</td>\n",
       "      <td>0.923052</td>\n",
       "      <td>-0.384674</td>\n",
       "      <td>-0.097276</td>\n",
       "      <td>0.995257</td>\n",
       "      <td>-0.997283</td>\n",
       "      <td>-0.073661</td>\n",
       "      <td>-0.330575</td>\n",
       "      <td>-0.943780</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004639</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.003478</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.002609</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.001956</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.001467</td>\n",
       "      <td>0.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.536573</td>\n",
       "      <td>0.843854</td>\n",
       "      <td>0.413275</td>\n",
       "      <td>-0.910606</td>\n",
       "      <td>0.448343</td>\n",
       "      <td>0.893862</td>\n",
       "      <td>-0.940067</td>\n",
       "      <td>0.340989</td>\n",
       "      <td>-0.607683</td>\n",
       "      <td>-0.794179</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005060</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.003795</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>0.002846</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.002134</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.420167</td>\n",
       "      <td>0.907447</td>\n",
       "      <td>-0.318216</td>\n",
       "      <td>-0.948018</td>\n",
       "      <td>0.855881</td>\n",
       "      <td>0.517173</td>\n",
       "      <td>-0.718144</td>\n",
       "      <td>0.695895</td>\n",
       "      <td>-0.824528</td>\n",
       "      <td>-0.565821</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005482</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.004111</td>\n",
       "      <td>0.999992</td>\n",
       "      <td>0.003083</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.002312</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.001734</td>\n",
       "      <td>0.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.990607</td>\n",
       "      <td>0.136737</td>\n",
       "      <td>-0.878990</td>\n",
       "      <td>-0.476839</td>\n",
       "      <td>0.999823</td>\n",
       "      <td>-0.018796</td>\n",
       "      <td>-0.370395</td>\n",
       "      <td>0.928874</td>\n",
       "      <td>-0.959605</td>\n",
       "      <td>-0.281349</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005904</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.004427</td>\n",
       "      <td>0.999990</td>\n",
       "      <td>0.003320</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.002490</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.001867</td>\n",
       "      <td>0.999998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.650288</td>\n",
       "      <td>-0.759688</td>\n",
       "      <td>-0.968206</td>\n",
       "      <td>0.250154</td>\n",
       "      <td>0.835838</td>\n",
       "      <td>-0.548975</td>\n",
       "      <td>0.042249</td>\n",
       "      <td>0.999107</td>\n",
       "      <td>-0.999519</td>\n",
       "      <td>0.031022</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006325</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>0.004743</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.003557</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.002667</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.999998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6   \\\n",
       "0   0.000000  1.000000  0.000000  1.000000  0.000000  1.000000  0.000000   \n",
       "1   0.841471  0.540302  0.681561  0.731761  0.533168  0.846009  0.409309   \n",
       "2   0.909297 -0.416147  0.997480  0.070948  0.902131  0.431463  0.746903   \n",
       "3   0.141120 -0.989992  0.778273 -0.627927  0.993253 -0.115966  0.953634   \n",
       "4  -0.756802 -0.653644  0.141539 -0.989933  0.778472 -0.627680  0.993281   \n",
       "5  -0.958924  0.283662 -0.571127 -0.820862  0.323935 -0.946079  0.858896   \n",
       "6  -0.279415  0.960170 -0.977396 -0.211416 -0.230368 -0.973104  0.574026   \n",
       "7   0.656987  0.753902 -0.859313  0.511449 -0.713721 -0.700430  0.188581   \n",
       "8   0.989358 -0.145500 -0.280228  0.959933 -0.977262 -0.212036 -0.229904   \n",
       "9   0.412118 -0.911130  0.449194  0.893434 -0.939824  0.341660 -0.608108   \n",
       "10 -0.544021 -0.839072  0.937633  0.347628 -0.612937  0.790132 -0.879767   \n",
       "11 -0.999990  0.004426  0.923052 -0.384674 -0.097276  0.995257 -0.997283   \n",
       "12 -0.536573  0.843854  0.413275 -0.910606  0.448343  0.893862 -0.940067   \n",
       "13  0.420167  0.907447 -0.318216 -0.948018  0.855881  0.517173 -0.718144   \n",
       "14  0.990607  0.136737 -0.878990 -0.476839  0.999823 -0.018796 -0.370395   \n",
       "15  0.650288 -0.759688 -0.968206  0.250154  0.835838 -0.548975  0.042249   \n",
       "\n",
       "          7         8         9   ...        54        55        56        57  \\\n",
       "0   1.000000  0.000000  1.000000  ...  0.000000  1.000000  0.000000  1.000000   \n",
       "1   0.912396  0.310984  0.950415  ...  0.000422  1.000000  0.000316  1.000000   \n",
       "2   0.664932  0.591127  0.806578  ...  0.000843  1.000000  0.000632  1.000000   \n",
       "3   0.300967  0.812649  0.582754  ...  0.001265  0.999999  0.000949  1.000000   \n",
       "4  -0.115730  0.953581  0.301137  ...  0.001687  0.999999  0.001265  0.999999   \n",
       "5  -0.512150  0.999947 -0.010342  ...  0.002108  0.999998  0.001581  0.999999   \n",
       "6  -0.818837  0.947148 -0.320796  ...  0.002530  0.999997  0.001897  0.999998   \n",
       "7  -0.982058  0.800422 -0.599437  ...  0.002952  0.999996  0.002214  0.999998   \n",
       "8  -0.973213  0.574318 -0.818632  ...  0.003374  0.999994  0.002530  0.999997   \n",
       "9  -0.793854  0.291259 -0.956644  ...  0.003795  0.999993  0.002846  0.999996   \n",
       "10 -0.475405 -0.020684 -0.999786  ...  0.004217  0.999991  0.003162  0.999995   \n",
       "11 -0.073661 -0.330575 -0.943780  ...  0.004639  0.999989  0.003478  0.999994   \n",
       "12  0.340989 -0.607683 -0.794179  ...  0.005060  0.999987  0.003795  0.999993   \n",
       "13  0.695895 -0.824528 -0.565821  ...  0.005482  0.999985  0.004111  0.999992   \n",
       "14  0.928874 -0.959605 -0.281349  ...  0.005904  0.999983  0.004427  0.999990   \n",
       "15  0.999107 -0.999519  0.031022  ...  0.006325  0.999980  0.004743  0.999989   \n",
       "\n",
       "          58        59        60        61        62        63  \n",
       "0   0.000000  1.000000  0.000000  1.000000  0.000000  1.000000  \n",
       "1   0.000237  1.000000  0.000178  1.000000  0.000133  1.000000  \n",
       "2   0.000474  1.000000  0.000356  1.000000  0.000267  1.000000  \n",
       "3   0.000711  1.000000  0.000533  1.000000  0.000400  1.000000  \n",
       "4   0.000949  1.000000  0.000711  1.000000  0.000533  1.000000  \n",
       "5   0.001186  0.999999  0.000889  1.000000  0.000667  1.000000  \n",
       "6   0.001423  0.999999  0.001067  0.999999  0.000800  1.000000  \n",
       "7   0.001660  0.999999  0.001245  0.999999  0.000933  1.000000  \n",
       "8   0.001897  0.999998  0.001423  0.999999  0.001067  0.999999  \n",
       "9   0.002134  0.999998  0.001600  0.999999  0.001200  0.999999  \n",
       "10  0.002371  0.999997  0.001778  0.999998  0.001334  0.999999  \n",
       "11  0.002609  0.999997  0.001956  0.999998  0.001467  0.999999  \n",
       "12  0.002846  0.999996  0.002134  0.999998  0.001600  0.999999  \n",
       "13  0.003083  0.999995  0.002312  0.999997  0.001734  0.999999  \n",
       "14  0.003320  0.999995  0.002490  0.999997  0.001867  0.999998  \n",
       "15  0.003557  0.999994  0.002667  0.999996  0.002000  0.999998  \n",
       "\n",
       "[16 rows x 64 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define Position Encoding look-up table\n",
    "context_length = 16\n",
    "position_encoding_lookup_table = torch.zeros(context_length, d_model)\n",
    "position = torch.arange(0, context_length, dtype=torch.float).unsqueeze(1)\n",
    "div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000) / d_model))\n",
    "#div_term_ = 1/(10000 ** (torch.arange(0, d_model, 2).float()/d_model))\n",
    "position_encoding_lookup_table[:, 0::2] = torch.sin(position * div_term)\n",
    "position_encoding_lookup_table[:, 1::2] = torch.cos(position * div_term)\n",
    "position_encoding_lookup_table = position_encoding_lookup_table.unsqueeze(0).expand(batch_size, -1, -1) #add batch dimension\n",
    "\n",
    "print(\"Position Encoding Look-up Table: \", position_encoding_lookup_table.shape) # [4, 16, 64] [batch_size, context_length, d_model]\n",
    "pd.DataFrame(position_encoding_lookup_table[0].detach().cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa43476e35fdb265",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T04:27:19.636816Z",
     "start_time": "2024-02-09T04:27:18.851615Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Illustration Purpose Only\n",
    "def visualize_pe(pe):\n",
    "    plt.imshow(pe, aspect=\"auto\")\n",
    "    plt.title(\"Positional Encoding\")\n",
    "    plt.xlabel(\"Encoding Dimension\")\n",
    "    plt.ylabel(\"Position Index\")\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "position_encoding_lookup_table2_np = position_encoding_lookup_table[0].cpu().numpy()\n",
    "visualize_pe(position_encoding_lookup_table2_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc5355ba995b07b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T04:28:10.855919Z",
     "start_time": "2024-02-09T04:28:10.789425Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add positional encoding into the input embedding vector\n",
    "input_embedding_x = x_batch_embedding + position_encoding_lookup_table.to(device) # [4, 16, 64] [batch_size, context_length, d_model]\n",
    "input_embedding_y = y_batch_embedding + position_encoding_lookup_table.to(device)\n",
    "pd.DataFrame(input_embedding_x[0].detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d8622d",
   "metadata": {},
   "source": [
    "### 多头注意力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49bfcfcb646b81f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T04:28:49.421348Z",
     "start_time": "2024-02-09T04:28:49.395576Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prepare Query, Key, Value for Multi-head Attention\n",
    "X = input_embedding_x\n",
    "query = key = value = X # [4, 16, 64] [batch_size, context_length, d_model]\n",
    "query.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37ba89375b2f44ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T04:28:52.125568Z",
     "start_time": "2024-02-09T04:28:51.769196Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-6df4b4543a82>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Define Query, Key, Value weight matrices # GPT3 在这个地方是12228*12228*3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mWq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mWk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mWv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "# Define Query, Key, Value weight matrices # GPT3 在这个地方是12228*12228*3 \n",
    "Wq = nn.Linear(d_model, d_model).to(device)\n",
    "Wk = nn.Linear(d_model, d_model).to(device)\n",
    "Wv = nn.Linear(d_model, d_model).to(device)\n",
    "\n",
    "Q = Wq(query).to(device) #[4, 16, 64]\n",
    "Q = Q.view(batch_size, -1, num_heads, d_model // num_heads)  #[4, 16, 4, 16]\n",
    "\n",
    "K = Wk(key).to(device) #[4, 16, 64]\n",
    "K = K.view(batch_size, -1, num_heads, d_model // num_heads)  #[4, 16, 4, 16]\n",
    "\n",
    "V = Wv(value).to(device)#[4, 16, 64]\n",
    "V = V.view(batch_size, -1, num_heads, d_model // num_heads)  #[4, 16, 4, 16]\n",
    "\n",
    "# print(torch.round(Q[0] * 100) / 100)\n",
    "qqq = Q.detach().cpu().numpy()\n",
    "pd.set_option('expand_frame_repr', False)\n",
    "for qs in qqq:\n",
    "    for qss in qs:\n",
    "        print(pd.DataFrame(qss))\n",
    "\n",
    "print(Q.shape) # [4, 16, 4, 16] [batch_size, context_length, num_heads, head_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b2187b2d310a2e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T04:29:30.525962Z",
     "start_time": "2024-02-09T04:29:30.508654Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Transpose q,k,v from [batch_size, context_length, num_heads, head_size] to [batch_size, num_heads, context_length, head_size]\n",
    "# The reason is that treat each batch with \"num_heads\" as its first dimension.\n",
    "Q = Q.transpose(1, 2) # [4, 4, 16, 16]\n",
    "K = K.transpose(1, 2) # [4, 4, 16, 16]\n",
    "V = V.transpose(1, 2) # [4, 4, 16, 16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd5217e3fa43d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T04:31:11.625621Z",
     "start_time": "2024-02-09T04:31:11.196103Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculate the attention score\n",
    "attention_score = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(d_model // num_heads) # [4, 4, 16, 16]\n",
    "\n",
    "# Illustration only\n",
    "plt.imshow(attention_score[1, 1].detach().cpu().numpy(), \"Accent\", aspect=\"auto\")\n",
    "plt.title(\"Attention(Q @ K)\") #plot attention in the first head of the first batch\n",
    "plt.xlabel(encoding.decode(x_batch[0].tolist()))\n",
    "plt.ylabel(encoding.decode(x_batch[0].tolist()))\n",
    "plt.colorbar()\n",
    "pd.DataFrame(attention_score[0][0].detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9958625c65291f4e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T04:31:43.305491Z",
     "start_time": "2024-02-09T04:31:42.713623Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Apply Mask to attention scores\n",
    "attention_score = attention_score.masked_fill(torch.triu(torch.ones(attention_score.shape[-2:]).to(device), diagonal=1).bool(), float('-inf'))#[4, 4, 16, 16] [batch_size, num_heads, context_length, context_length]\n",
    "\n",
    "# Illustration only\n",
    "plt.imshow(attention_score[1, 1].detach().cpu().numpy(), \"Accent\", aspect=\"auto\")\n",
    "plt.title(\"Attention(Q,K)\")\n",
    "plt.xlabel(encoding.decode(x_batch[0].tolist()))\n",
    "plt.ylabel(encoding.decode(x_batch[0].tolist()))\n",
    "plt.colorbar()\n",
    "pd.DataFrame(attention_score[0][0].detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb3f22c3466b59b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T04:32:08.443877Z",
     "start_time": "2024-02-09T04:32:08.408750Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Softmax the attention score\n",
    "attention_score = torch.softmax(attention_score, dim=-1) #[4, 4, 16, 16] [batch_size, num_heads, context_length, context_length]\n",
    "pd.DataFrame(attention_score[0][0].detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d81a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertviz import head_view\n",
    "\n",
    "att_first_head = [attention_score[i].unsqueeze(0) for i in range(batch_size)]\n",
    "print(att_first_head[0].shape)\n",
    "\n",
    "token_list = [[encoding.decode_single_token_bytes(i).decode('utf-8')] for i in x_batch[0].tolist()]\n",
    "head_view(att_first_head, token_list, prettify_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a14ab6238d8f340",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T04:32:19.745362Z",
     "start_time": "2024-02-09T04:32:19.729817Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculate the V attention output\n",
    "print(attention_score.shape) #[4, 4, 16, 16] [batch_size, num_heads, context_length, context_length]\n",
    "print(V.shape) #[4, 4, 16, 16] [batch_size, num_heads, context_length, head_size]\n",
    "A = torch.matmul(attention_score, V) # [4, 4, 16, 16] [batch_size, num_heads, context_length, head_size]\n",
    "print(A.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57894d06f08e7f5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T04:32:38.040254Z",
     "start_time": "2024-02-09T04:32:37.994213Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Concatenate the attention output\n",
    "A = A.transpose(1, 2) # [4, 16, 4, 16] [batch_size, context_length, num_heads, head_size]\n",
    "A = A.reshape(batch_size, -1, d_model) # [4, 16, 64] [batch_size, context_length, d_model]\n",
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4fbfce6f7f330a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T04:33:01.895820Z",
     "start_time": "2024-02-09T04:33:01.830312Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define the output weight matrix  \n",
    "Wo = nn.Linear(d_model, d_model).to(device)\n",
    "output = Wo(A) # [4, 16, 64] [batch_size, context_length, d_model]\n",
    "print(output.shape)\n",
    "pd.DataFrame(output[0].detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2835a23754fafc42",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T04:34:34.038171Z",
     "start_time": "2024-02-09T04:34:34.029896Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add residual connection\n",
    "output = output + X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da2ac57",
   "metadata": {},
   "source": [
    "### 层归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7761664159de5538",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T04:34:34.636527Z",
     "start_time": "2024-02-09T04:34:34.608438Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add Layer Normalization\n",
    "layer_norm = nn.LayerNorm(d_model).to(device)\n",
    "output_layernorm = layer_norm(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2c0c08",
   "metadata": {},
   "source": [
    "### FFN 全连接网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce7c56ac3de91a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T04:34:35.139721Z",
     "start_time": "2024-02-09T04:34:35.110122Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define Feed Forward Network\n",
    "output = nn.Linear(d_model, d_model * 4).to(device)(output_layernorm)\n",
    "output = nn.ReLU()(output)#GPT2 使用的是GELU\n",
    "output = nn.Linear(d_model * 4, d_model).to(device)(output)\n",
    "output = torch.dropout(output, p=dropout, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cce4d92eeb74ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T04:35:25.104704Z",
     "start_time": "2024-02-09T04:35:25.076394Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add residual connection & layerNorm (last time in a Transformer block)\n",
    "output = output + output_layernorm\n",
    "# Add Layer Normalization\n",
    "layer_norm = nn.LayerNorm(d_model).to(device)\n",
    "output = layer_norm(output)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30433ac",
   "metadata": {},
   "source": [
    "### 输出映射到词表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4b434e547757",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T04:35:26.555049Z",
     "start_time": "2024-02-09T04:35:26.440498Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Apply the final linear layer to get the logits\n",
    "logits = nn.Linear(d_model, max_token_value+1).to(device)(output)\n",
    "pd.DataFrame(logits[0].detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a857abd1cceecb4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T04:35:46.352818Z",
     "start_time": "2024-02-09T04:35:46.256747Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get the probabilities \n",
    "# torch.softmax usually used during inference, during training we use torch.nn.CrossEntropyLoss\n",
    "# but for illustration purpose, we'll use torch.softmax here\n",
    "probabilities = torch.softmax(logits, dim=-1)\n",
    "pd.DataFrame(probabilities[0].detach().cpu().numpy())\n",
    "probabilities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de9e0455613f790",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T04:36:08.064535Z",
     "start_time": "2024-02-09T04:36:08.045119Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's see the predicted token and it's original English word\n",
    "predicted_index = torch.argmax(probabilities[0,0]).item()\n",
    "encoding.decode([predicted_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329ff8f3529b7309",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T04:39:04.969636Z",
     "start_time": "2024-02-09T04:39:04.925038Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's see the original input sentence\n",
    "print(encoding.decode(x_batch[0].tolist()))\n",
    "print(encoding.decode(y_batch[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df84e5a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
